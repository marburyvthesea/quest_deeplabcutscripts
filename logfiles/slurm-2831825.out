Module is experimental. 
config file is: /projects/p30771/dlc_analysis/Test_dlc-Santiago-2020-10-06/config.yaml
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/jma819/.conda/envs/tensorflow-gpu-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
0it [00:00, ?it/s]1it [00:02,  2.90s/it]2it [00:03,  2.10s/it]3it [00:03,  1.52s/it]4it [00:03,  1.12s/it]5it [00:03,  1.18it/s]6it [00:03,  1.54it/s]7it [00:04,  1.95it/s]8it [00:04,  2.42it/s]9it [00:04,  2.82it/s]10it [00:04,  3.30it/s]11it [00:04,  3.66it/s]12it [00:05,  4.08it/s]13it [00:05,  4.06it/s]14it [00:05,  4.33it/s]15it [00:05,  4.46it/s]16it [00:05,  4.51it/s]17it [00:06,  4.73it/s]18it [00:06,  4.72it/s]19it [00:06,  4.82it/s]20it [00:06,  4.94it/s]
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:00<00:16,  1.18it/s] 10%|█         | 2/20 [00:01<00:13,  1.35it/s] 15%|█▌        | 3/20 [00:01<00:11,  1.54it/s] 20%|██        | 4/20 [00:02<00:09,  1.72it/s] 25%|██▌       | 5/20 [00:02<00:08,  1.87it/s] 30%|███       | 6/20 [00:03<00:07,  1.99it/s] 35%|███▌      | 7/20 [00:03<00:06,  2.08it/s] 40%|████      | 8/20 [00:03<00:05,  2.15it/s] 45%|████▌     | 9/20 [00:04<00:04,  2.20it/s] 50%|█████     | 10/20 [00:04<00:04,  2.06it/s] 55%|█████▌    | 11/20 [00:05<00:04,  2.13it/s] 60%|██████    | 12/20 [00:05<00:03,  2.19it/s] 65%|██████▌   | 13/20 [00:06<00:03,  2.23it/s] 70%|███████   | 14/20 [00:06<00:02,  2.27it/s] 75%|███████▌  | 15/20 [00:07<00:02,  2.29it/s] 80%|████████  | 16/20 [00:07<00:01,  2.31it/s] 85%|████████▌ | 17/20 [00:07<00:01,  2.31it/s] 90%|█████████ | 18/20 [00:08<00:00,  2.31it/s] 95%|█████████▌| 19/20 [00:08<00:00,  2.31it/s]100%|██████████| 20/20 [00:09<00:00,  2.32it/s]
DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)
Running  DLC_resnet50_Test_dlcOct6shuffle1_300000  with # of trainingiterations: 300000
Initializing ResNet
Analyzing data...
Done and results stored for snapshot:  snapshot-300000
Results for 300000  training iterations: 95 1 train error: 1.87 pixels. Test error: 6.38  pixels.
With pcutoff of 0.6  train error: 1.87 pixels. Test error: 6.38 pixels
Thereby, the errors are given by the average distances between the labels by DLC and the scorer.
Plotting...
The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.
If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.
Use the function 'analyze_video' to make predictions on new videos.
Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)
finished evaluating
